from bs4 import BeautifulSoup
import requests
from fake_useragent import UserAgent
from lxml import etree

ua=UserAgent()
kv={'user-agent':ua.random}



def getHtmlText(start_url):
    '''
    获取HTML
    '''
    try:
        r=requests(url,headers=kv)
        r


def paserPage(picList,html):
    '''
    解析清洗页面
    '''

def savePic(picList):
    '''
    存储图片
    '''

if __name__ == "__main__":
    '''
    主程序
    '''
    depth=3
    start_url='http://jandan.net/ooxx'
    picList=[]
    for i in range(depth):
        try:
            url=start_url+




http://jandan.net/ooxx/MjAyMDA2MDItMTQ4#comments
http://jandan.net/ooxx/MjAyMDA2MDItMTQ3#comments
http://jandan.net/ooxx/MjAyMDA2MDItMTQ2#comments
http://jandan.net/ooxx/MjAyMDA2MDItMTQ1#comments
http://jandan.net/ooxx/MjAyMDA2MDItMTQ0#comments
http://jandan.net/ooxx/MjAyMDA2MDItMTQz#comments
http://jandan.net/ooxx/MjAyMDA2MDItMTQy#comments
http://jandan.net/ooxx/MjAyMDA2MDItMTQx#comments
http://jandan.net/ooxx/MjAyMDA2MDItMTQw#comments
http://jandan.net/ooxx/MjAyMDA2MDItMTM5#comments
http://jandan.net/ooxx/MjAyMDA2MDItMTM4#comments
http://jandan.net/ooxx/MjAyMDA2MDItMTMz#comments
