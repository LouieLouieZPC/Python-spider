# 爬取网页的通用代码框架

使得用户爬取网页更稳定、可靠

## 一、基础

1. Requests库支持6种常用的异常：

|异常|说明|
|---|---|
|requests.ConnectionError|网络连接异常，如DNS查询失败，拒绝连接等|
|requests.HTTPError|HTTP错误异常|
|requests.URLRequired|URL缺失异常|
|requests.TooManyRedirects|超过最大重定向次数，产生重定向异常|
|requests.ConnectTimeout|连接远程服务器超时异常|
|requests.Timeout|请求URL超时，产生超时异常|


2. Response对象的一个方法：  
`r.raise_for_status()`   :如果`status_code`不是200，产生异常`request.HTTPError`


3.e.g.:
```python
import requests
from requests.exceptions import ReadTimeout,ConnectTimeout,RequestException     # 导入request.exceptions下的各种异常错误下的各种异常错误


try:      # 把请求放在try下
    response=requests.get('http://httpbin.org/get',timeout=0.5)
    print(response.status_code)
except ReadTimeout:    # 把可能发生的异常用except获取
    print('Timeout')    # 超时异常
except ConnectTimeout: # 把可能发生的异常用except获取
    print('Connection error')    # 连接异常
except RequestException:  # 把可能发生的异常用except获取
    print('Error')      # 请求异常
```




## 二、爬取网页的通用代码框架：
```python
import requests
def getHTMLText(url):
    try:
        r=requests.get(url,timeout=20)
        r.raise_for_status()   # 👍如果状态不是200，引发HTTPError异常
        r.encoding=r.apparent_encoding
        return r.text
    except:                   # 把可能发生的异常用except获取
        return '产生异常(raise exception)'

if __name__ == "__main__":
    url='http://www.baidu.com'
    print(getHTMLText(url))
```