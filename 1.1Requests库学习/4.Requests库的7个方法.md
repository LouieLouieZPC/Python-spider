# Requests库7个主要方法解析

## 一、request方法：

__格式：__
`request.request(method,url,**kwargs)`


> r = requests.request(method='GET', url=url, **kwargs)  
> r = requests.get(url, **kwargs)  
> PS：上面的方法和下面的方法达到的效果是一样的，就是做了一层封装，把比较常用的方法都抽出来,  

* `method`:请求方式，对应HTTP协议请求方法get/put/post等7种请求方法，例如：request.request('GET',url,**kwargs) ，（Requests库的方法为小写，而HTTP协议请求方法为大写）
* `url`：拟获取页面的URL链接
* `**kwargs`：控制访问参数，共13个:
  - `params`:字典或字节序列(字符串)，作为参数增加至URL中(搭配get)
  - `data`:字典(被放进form)或字节序列(字符串)（被放进data）或文件对象，作为Request的内容text（搭配put）
  - `json`:JSON格式的数据，作为Request的内容text（json格式，其实就是字符串）（搭配post）
  - `headers`:字典，HTTP定制头部，隐藏爬虫信息，模拟浏览器的头部信息（搭配post）
  - `cookies`:字典或CookieJar,Request中的cookie（搭配post）
  - `auth`: 元祖，支持HTTP认证功能(搭配get)
  - `files`: 字典类型，传输文件（搭配post）
  - `timeout`: 设定超时时间，秒为单位(搭配get)
  - `proxies`: 字典类型，设定访问代理服务器，可以增加登录认证,proxies即代理人(搭配get)
  - `allow_redirects`: True/False,默认为True,重定向开关(搭配get)
  - `stream`: True/False，默认为True,获取内容立即下载开关(搭配get)
  - `verity`: True/False默认Ture,认证ssl证书开关(搭配get)
  - `cert`: 本地ssl证书路径(搭配get)




************************************************************





### （一）e.g.:`params`介绍
```python
import requests


kv={'key1':'value1','key2':'value2'}

r=requests.request('GET','http://python123.io/ws',params=kv)   
print(r.url)


# Output:
https://python123.io/ws?key1=value1&key2=value2
```






*******************************************************************************************






### （二）e.g.:`date`介绍
```python
import requests

kv={'key1':'value1','key2':'value2'}

r=requests.request('PUT','http://httpbin.org/put',data=kv)   
print(r.status_code)
print(r.text)


# Output:
200
{
  "args": {},
  "data": "",
  "files": {},
  "form": {
    "key1": "value1",
    "key2": "value2"
  },
  "headers": {
    "Accept": "*/*",
    "Accept-Encoding": "gzip, deflate",
    "Content-Length": "23",
    "Content-Type": "application/x-www-form-urlencoded",
    "Host": "httpbin.org",
    "User-Agent": "python-requests/2.22.0",
    "X-Amzn-Trace-Id": "Root=1-5e4a8581-cb3c8890bd750450bacc8820"
  },
  "json": null,
  "origin": "218.72.109.87",
  "url": "http://httpbin.org/put"

}
```





************************************************************************************************






###（三）e.g.:`headers`介绍
```python
In [58]: url = 'http://httpbin.org/post'

In [59]: r = requests.request('POST', url)

# 头部信息
In [69]: r.request.headers   # r.request.headers是请求头(request headers)，而r.headers是响应头(response headers)
# 观察User-Agent
Out[69]: {'Accept': '*/*', 'User-Agent': 'python-requests/2.13.0', 'Connection': 'keep-alive', 'Accept-Encoding': 'gzip, deflate', 'Content-Length': '0'}

-------------------------------------------------------------------------------------------------
#加入headers后
In [62]: headers = { # 浏览器代理
    ...:      "User-Agent": "Mozilla/5.0 (Windows NT 6.1; WOW64) AppleWebKit/537.36 (KHTML, like Gecko) Ch
    ...: rome/57.0.2987.133 Safari/537.36"
    ...: }
In [63]: r = requests.request('POST', url, headers=headers)

In [71]: r.request.headers       # 查看请求头
Out[71]: {'Accept': '*/*', 'User-Agent': 'Mozilla/5.0 (Windows NT 6.1; WOW64) AppleWebKit/537.36 (KHTML, like Gecko) Chrome/57.0.2987.133 Safari/537.36', 'Connection': 'keep-alive', 'Accept-Encoding': 'gzip, deflate', 'Content-Length': '0'}
```





**************************************************************************************************






### （四）e.g.:`cookie`介绍
```python
#先获取百度的cookie，当我们使用电脑进行浏览网页的时候，服务器就会生成一个证书，并且返回给我们的电脑（响应），这个证书就是cookie，一般情况下，cookie是服务器写入客户端的文件，我们也可以叫浏览器缓存。用户在下次访问的时候，就会把本地的cookie文件加上url一起发送给服务器，服务器以此来判断用户的状态。
In [74]: r = requests.request('GET', 'https://www.baidu.com')

In [75]: r
Out[75]: <Response [200]>
# 保存在变量中
In [76]: cookie = r.cookies       # 将r的cookies属性存储在变量cookie里

# cookie类型           
In [86]: type(cookie)
Out[86]: requests.cookies.RequestsCookieJar


In [77]: r_baidu = requests.request('POST', 'https://www.baidu.com/s?ie=utf-8&f=8&rsv_bp=0&rsv_idx=1&tn=baidu&wd=old&rsv_pq=981edbe6000308e9&rsv_t=76c1VG%2B1PcKzCGSEjcf3W2zDn5ZcBnhR1TAe%2FcJ32OW62aKsa5DWo7YYsms&rqlang=cn&rsv_enter=1&rsv_sug3=2', cookie=cookie)
# https://www.baidu.com/s?ie=utf-8&f=8&rsv_bp=0&rsv_idx=1&tn=baidu&wd=test&rsv_pq=981edbe6000308e9&rsv_t=76c1VG%2B1PcKzCGSEjcf3W2zDn5ZcBnhR1TAe%2FcJ32OW62aKsa5DWo7YYsms&rqlang=cn&rsv_enter=1&rsv_sug3=2 中 wd修改关键词w为old 就是提交给百度进行搜索old的内容

```




**************************************************************************************************





### （五）e.g.:`auth`介绍
```python
import requests
# 最简单的http验证
from requests.auth import HTTPBasicAuth

r = requests.get('http://httpbin.org/auth', auth=HTTPBasicAuth('user', 'user'))
# r = requests.get('http://httpbin.org/auth', auth=('user', 'user'))
print(r.status_code)

```


*******************************************************************************


### （六）e.g.:`files`介绍

```python
fs = {file: open('data.xls', 'rb')}        # .xls是一个特有的二进制格式，'rb'为为读取二进制文件
# 使用files参数就可以了
r = requests.request('POST','http://httpbin.org/post',files=fs)       # files=字典
```


***********************************************************************************


### （七）e.g.:`timeout`介绍
```python
import requests
from requests.exceptions import ReadTimeout     # 导入request.exceptions下的各种异常错误下的各种异常错误

try:     # 把请求放在try下
  # 设置必须在500ms内收到响应，不然或抛出ReadTimeout异常
  response = requests.get("http://httpbin.org/get", timeout=0.5)
           print(response.status_code)
except ReadTimeout:   # 把可能发生的异常用except获取：s
  print('Timeout')
```


***********************************************************************************


### （八）e.g.:`proxies`介绍
```python
import requests

#普通代理
proxies = {
   "http": "http://127.0.0.1:1080",
   "https": "https://127.0.0.1:1080",
}
# 往请求中设置代理(proxies)
r = requests.get("https://www.taobao.com", proxies=proxies)
print(r.status_code)
---------------------------------------------------------------
# 带有用户名和密码的代理
proxies = {
   "http": "http://user:password@127.0.0.1:9743/",
}
r = requests.get("https://www.taobao.com", proxies=proxies)
print(r.status_code)
---------------------------------------------------------------
# 设置socks代理,翻墙必备
proxies = {
   'http': 'socks5://127.0.0.1:1080',
   'https': 'socks5://127.0.0.1:1080'
}
r = requests.get("https://www.google.com", proxies=proxies)
print(r.status_code)
```


***********************************************************************************


### （九）e.g.:`allow_redirects`介绍:True/False,默认为True,重定向开关
```python
r = requests.request('GET','http://httpbin.org/get',allow_redirects=False)
```


***********************************************************************************



### （七）e.g.:`stream`介绍True/False，默认为True,获取内容立即下载开关
```python
r = requests.request('GET','http://httpbin.org/get/**.txt',stream=False)
```


***********************************************************************************



### （七）e.g.:`verity`介绍:True/False默认Ture,认证ssl证书开关
```python
import requests
# 无证书访问
r = requests.get('https://www.12306.cn')
# 在请求https时，request会进行证书的验证，如果验证失败则会抛出异常
print(r.status_code)
---------------------------------------------------------------

# 关闭验证，但是仍然会报出证书警告(不安全的请求警告)
r = requests.get('https://www.12306.cn',verify=False)
print(r.status_code)
----------------------------------------------------------------
# 消除关闭证书验证的警告
from requests.packages import urllib3

# 关闭警告
urllib3.disable_warnings()
r = requests.get('https://www.12306.cn',verify=False)
print(r.status_code)
```


